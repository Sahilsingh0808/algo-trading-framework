{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy matplotlib yfinance"
      ],
      "metadata": {
        "id": "q-yRfc1HaNKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XZICm1wMfnp"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import logging\n",
        "# from kiteconnect import KiteConnect\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---------------------------------------------\n",
        "# CONFIGURATIONS & USER INPUTS\n",
        "# ---------------------------------------------"
      ],
      "metadata": {
        "id": "UWjAlJ6pNqpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trading Mode: 'capital' or 'quantity'\n",
        "TRADING_MODE = 'quantity'  # Change to 'capital' for capital-based trading\n",
        "\n",
        "# Parameters for Capital-Based Trading\n",
        "Y_CAPITAL = 100000.0          # Total capital dedicated to this strategy in INR\n",
        "\n",
        "# Parameters for Quantity-Based Trading\n",
        "QUANTITY = 1000                 # Fixed number of shares to trade\n",
        "\n",
        "# Common Strategy Parameters\n",
        "INSTRUMENT = \"NSE:SBIN\"\n",
        "X_PROFIT = 2.0\n",
        "RSI_PERIOD = 14\n",
        "SUPER_TREND_PERIOD = 10\n",
        "SUPER_TREND_MULTIPLIER = 3\n",
        "TIMEFRAME = \"5minute\"\n",
        "RSI_BUY_THRESHOLD = 30 #make a range here\n",
        "RSI_SELL_THRESHOLD = 60\n",
        "STOP_LOSS = 10.0\n",
        "CHECK_INTERVAL = 0\n",
        "\n",
        "# CSV with historical data for paper trading\n",
        "CSV_FILE = \"sbin_ns.csv\"     # Replace with your actual historical data file\n",
        "\n",
        "# Output report file\n",
        "REPORT_FILE_TXT = \"trade_report.txt\"\n",
        "REPORT_FILE = \"trade_report.csv\""
      ],
      "metadata": {
        "id": "dtUFywGKNH98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---------------------------------------------\n",
        "# LOGGING CONFIG\n",
        "# ---------------------------------------------"
      ],
      "metadata": {
        "id": "MJk7dlpiNu8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s]: %(message)s')\n",
        "# Configure logging\n",
        "logging.basicConfig(filename='app.log',\n",
        "                    level=logging.DEBUG,\n",
        "                    force=True, # Resets any previous configuration\n",
        "                    )\n",
        "\n",
        "logging.info(\"Logging is set up and ready!\")"
      ],
      "metadata": {
        "id": "mOM4D46ANyek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---------------------------------------------\n",
        "# KITE CONNECT SETUP\n",
        "# ---------------------------------------------"
      ],
      "metadata": {
        "id": "Iry2xb4MPd_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kite = None\n",
        "if TRADING_MODE == 'capital' or TRADING_MODE == 'quantity':\n",
        "    # Assuming live trading requires Kite API credentials\n",
        "    # For paper trading, these are not required\n",
        "    pass\n",
        "\n",
        "# For live trading, uncomment and set your API credentials\n",
        "# API_KEY = \"your_api_key_here\"\n",
        "# API_SECRET = \"your_api_secret_here\"\n",
        "# ACCESS_TOKEN = \"your_access_token_here\"\n",
        "\n",
        "# Uncomment the following block for live trading setup\n",
        "# if TRADING_MODE == 'live':\n",
        "#     if not API_KEY or not API_SECRET or not ACCESS_TOKEN:\n",
        "#         logging.error(\"API_KEY, API_SECRET, ACCESS_TOKEN must be set for live trading!\")\n",
        "#         raise ValueError(\"Invalid API keys or tokens for live trading.\")\n",
        "#\n",
        "#     kite = KiteConnect(api_key=API_KEY)\n",
        "#     kite.set_access_token(ACCESS_TOKEN)\n",
        "#     # Test the connection\n",
        "#     try:\n",
        "#         profile = kite.profile()\n",
        "#         logging.info(f\"Successfully authenticated with Zerodha. User: {profile['user_name']}\")\n",
        "#     except Exception as e:\n",
        "#         logging.error(f\"Failed to authenticate with Zerodha: {e}\")\n",
        "#         raise e"
      ],
      "metadata": {
        "id": "O8D08-_aPeqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---------------------------------------------\n",
        "# PAPER DATA HANDLER (For Paper Trading)\n",
        "# ---------------------------------------------"
      ],
      "metadata": {
        "id": "Am4L15fjPkcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PaperDataHandler:\n",
        "    \"\"\"\n",
        "    Simulates fetching of historical and 'live' data from a local CSV for paper trading.\n",
        "    - Loads a CSV with OHLC data.\n",
        "    - Provides methods to get the latest candle slice for RSI calculation.\n",
        "    - Provides a method to get the current LTP (simulated as the close of the latest candle).\n",
        "    - Advances a pointer through the CSV rows to simulate time passing.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, csv_file):\n",
        "        self.csv_file = csv_file\n",
        "        self.df = None\n",
        "        self.current_index = None\n",
        "        self.load_data()\n",
        "\n",
        "    def load_data(self):\n",
        "      if not os.path.exists(self.csv_file):\n",
        "          logging.error(f\"CSV file {self.csv_file} not found. Exiting gracefully...\")\n",
        "          self.df = pd.DataFrame()\n",
        "          return\n",
        "\n",
        "      self.df = pd.read_csv(self.csv_file)\n",
        "\n",
        "      # Convert column names to lowercase\n",
        "      self.df.columns = map(str.lower, self.df.columns)\n",
        "\n",
        "      # Validate data\n",
        "      required_cols = {'date', 'open', 'high', 'low', 'close', 'volume'}\n",
        "      if not required_cols.issubset(set(self.df.columns)):\n",
        "          logging.error(f\"CSV file {self.csv_file} does not have the required columns: {required_cols}\")\n",
        "          self.df = pd.DataFrame()\n",
        "          return\n",
        "\n",
        "      # Handle date parsing with error handling\n",
        "      try:\n",
        "          self.df['date'] = pd.to_datetime(self.df['date'], dayfirst=True, errors='coerce')\n",
        "      except Exception as e:\n",
        "          logging.error(f\"Error parsing dates: {e}\")\n",
        "          self.df = pd.DataFrame()\n",
        "          return\n",
        "\n",
        "      # Drop rows where date parsing failed\n",
        "      if self.df['date'].isnull().any():\n",
        "          logging.warning(f\"Some rows have invalid date formats and will be dropped.\")\n",
        "          self.df = self.df.dropna(subset=['date'])\n",
        "\n",
        "      # Sort by date if not sorted\n",
        "      self.df = self.df.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "      if self.df.empty:\n",
        "          logging.error(\"CSV data is empty after processing. Exiting...\")\n",
        "          return\n",
        "\n",
        "      # Start from the RSI_PERIOD-th candle to have enough data for RSI calculation\n",
        "      self.current_index = RSI_PERIOD\n",
        "\n",
        "    def get_historical_candles(self, lookback=100):\n",
        "        \"\"\"\n",
        "        Returns a historical slice of candles up to current_index for RSI calculation.\n",
        "        If current_index is None or data insufficient, return empty df.\n",
        "        \"\"\"\n",
        "        if self.df.empty or self.current_index is None:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        start_idx = max(0, self.current_index - lookback)\n",
        "        return self.df.iloc[start_idx:self.current_index]\n",
        "\n",
        "    def get_current_ltp(self):\n",
        "        \"\"\"\n",
        "        Returns the current candle's close price as LTP.\n",
        "        If no more data is available, return None.\n",
        "        \"\"\"\n",
        "        if self.df.empty or self.current_index is None:\n",
        "            return None\n",
        "        if self.current_index >= len(self.df):\n",
        "            return None\n",
        "        return self.df.iloc[self.current_index]['close']\n",
        "\n",
        "    def advance_time(self):\n",
        "        \"\"\"\n",
        "        Move to the next candle, simulating passing of time.\n",
        "        If no more data, return False to indicate we are done.\n",
        "        \"\"\"\n",
        "        if self.df.empty or self.current_index is None:\n",
        "            return False\n",
        "        self.current_index += 1\n",
        "        if self.current_index >= len(self.df):\n",
        "            # No more data available\n",
        "            return False\n",
        "        return True"
      ],
      "metadata": {
        "id": "nzS1XUtOPlIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize PaperDataHandler if PAPER_TRADING"
      ],
      "metadata": {
        "id": "4WimG3ivPwOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paper_data_handler = None\n",
        "if TRADING_MODE in ['capital', 'quantity']:\n",
        "    paper_data_handler = PaperDataHandler(CSV_FILE)"
      ],
      "metadata": {
        "id": "EOMzrCKbPxI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f25568-a8a5-4446-8cf4-2ea78ba2ab16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-c9a76506c313>:36: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S%z format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
            "  self.df['date'] = pd.to_datetime(self.df['date'], dayfirst=True, errors='coerce')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---------------------------------------------\n",
        "# VALIDATIONS\n",
        "# ---------------------------------------------"
      ],
      "metadata": {
        "id": "lk55him9N1n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if TRADING_MODE not in ['capital', 'quantity']:\n",
        "    logging.error(\"Invalid TRADING_MODE. Choose 'capital' or 'quantity'.\")\n",
        "    raise ValueError(\"Invalid TRADING_MODE. Choose 'capital' or 'quantity'.\")\n",
        "\n",
        "if TRADING_MODE == 'capital' and Y_CAPITAL <= 0:\n",
        "    logging.error(\"Y_CAPITAL must be a positive number for capital-based trading.\")\n",
        "    raise ValueError(\"Invalid Y_CAPITAL for capital-based trading.\")\n",
        "\n",
        "if TRADING_MODE == 'quantity' and (not isinstance(QUANTITY, int) or QUANTITY <= 0):\n",
        "    logging.error(\"QUANTITY must be a positive integer for quantity-based trading.\")\n",
        "    raise ValueError(\"Invalid QUANTITY for quantity-based trading.\")\n"
      ],
      "metadata": {
        "id": "XuIJIc_pN3-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---------------------------------------------\n",
        "# HELPER FUNCTIONS\n",
        "# ---------------------------------------------"
      ],
      "metadata": {
        "id": "224xMRqWN8RV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_rsi(series, period=14):\n",
        "    \"\"\"\n",
        "    Calculate RSI for the given price series.\n",
        "    \"\"\"\n",
        "    delta = series.diff().dropna()\n",
        "    up = delta.where(delta > 0, 0.0)\n",
        "    down = -delta.where(delta < 0, 0.0)\n",
        "    gain = up.rolling(window=period, min_periods=1).mean()\n",
        "    loss = down.rolling(window=period, min_periods=1).mean()\n",
        "    RS = gain / loss\n",
        "    RSI = 100.0 - (100.0 / (1.0 + RS))\n",
        "    return RSI\n",
        "\n",
        "def get_latest_candles():\n",
        "    \"\"\"\n",
        "    Fetch historical data for RSI calculation:\n",
        "    - In paper mode, fetch from the PaperDataHandler.\n",
        "    - In live mode, fetch from Zerodha (not implemented here).\n",
        "    \"\"\"\n",
        "    if TRADING_MODE in ['capital', 'quantity']:\n",
        "        df = paper_data_handler.get_historical_candles()\n",
        "        return df\n",
        "    else:\n",
        "        # Implement live mode historical fetch if needed\n",
        "        return None\n",
        "\n",
        "def fetch_ltp():\n",
        "    \"\"\"\n",
        "    Get the current LTP.\n",
        "    - In paper mode, from PaperDataHandler.\n",
        "    - In live mode, from kite.ltp.\n",
        "    \"\"\"\n",
        "    if TRADING_MODE in ['capital', 'quantity']:\n",
        "        ltp = paper_data_handler.get_current_ltp()\n",
        "        return ltp\n",
        "    else:\n",
        "        try:\n",
        "            data = kite.ltp(INSTRUMENT)\n",
        "            return data[INSTRUMENT]['last_price']\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error fetching LTP: {e}\")\n",
        "            return None\n",
        "\n",
        "def place_order(transaction_type, quantity, price=None):\n",
        "    \"\"\"\n",
        "    Simulate or place a market order.\n",
        "    \"\"\"\n",
        "    if TRADING_MODE in ['capital', 'quantity']:\n",
        "        # Paper Trading: Simulate order\n",
        "        mock_order_id = f\"mock_{transaction_type}_{int(time.time())}\"\n",
        "        logging.info(f\"(Paper Trade) Order Placed: {transaction_type} Qty: {quantity}, ID: {mock_order_id}\")\n",
        "        return mock_order_id\n",
        "    else:\n",
        "        # Live Trading: Place order via Kite API\n",
        "        try:\n",
        "            order_id = kite.place_order(\n",
        "                variety=kite.VARIETY_REGULAR,\n",
        "                exchange=\"NSE\",\n",
        "                tradingsymbol=INSTRUMENT.split(':')[-1],\n",
        "                transaction_type=transaction_type,\n",
        "                quantity=quantity,\n",
        "                order_type=kite.ORDER_TYPE_MARKET,\n",
        "                product=kite.PRODUCT_MIS\n",
        "            )\n",
        "            logging.info(f\"Order placed. Type: {transaction_type}, Qty: {quantity}, ID: {order_id}\")\n",
        "            return order_id\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Order placement failed: {e}\")\n",
        "            return None\n",
        "\n",
        "def calculate_supertrend(df, period=10, multiplier=3):\n",
        "    hl2 = (df['high'] + df['low']) / 2\n",
        "    atr = (df['high'] - df['low']).rolling(window=period).mean()\n",
        "    upper_band = hl2 + (multiplier * atr)\n",
        "    lower_band = hl2 - (multiplier * atr)\n",
        "    df['supertrend'] = np.nan\n",
        "    in_uptrend = True\n",
        "    for i in range(1, len(df)):\n",
        "        if df['close'].iloc[i] > upper_band.iloc[i - 1]:\n",
        "            in_uptrend = True\n",
        "        elif df['close'].iloc[i] < lower_band.iloc[i - 1]:\n",
        "            in_uptrend = False\n",
        "        df.loc[i, 'supertrend'] = lower_band.iloc[i] if in_uptrend else upper_band.iloc[i]\n",
        "    df['trend'] = np.where(df['close'] > df['supertrend'], 'up', 'down')\n",
        "    return df"
      ],
      "metadata": {
        "id": "ly0AVgPbN6M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---------------------------------------------\n",
        "# TRADE ANALYTICS\n",
        "# ---------------------------------------------\n",
        "# We'll store each completed trade in a list of dicts for analysis at the end."
      ],
      "metadata": {
        "id": "ZOsg1VFiU28R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trades = []"
      ],
      "metadata": {
        "id": "9X2CgFckU35j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---------------------------------------------\n",
        "# TRADE ANALYTICS & REPORTING\n",
        "# ---------------------------------------------"
      ],
      "metadata": {
        "id": "8uq8lD-KVCz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_trade_report(trades, total_realized_pnl):\n",
        "    if not trades:\n",
        "        logging.info(\"No trades were executed. No analytics available.\")\n",
        "        return\n",
        "\n",
        "    # Convert to DataFrame for easier analysis\n",
        "    trades_df = pd.DataFrame(trades)\n",
        "\n",
        "    total_trades = len(trades_df)\n",
        "    wins = trades_df[trades_df['pnl'] > 0].shape[0]\n",
        "    losses = trades_df[trades_df['pnl'] < 0].shape[0]\n",
        "    win_rate = (wins / total_trades) * 100 if total_trades > 0 else 0.0\n",
        "    avg_win = trades_df[trades_df['pnl'] > 0]['pnl'].mean() if wins > 0 else 0.0\n",
        "    avg_loss = trades_df[trades_df['pnl'] < 0]['pnl'].mean() if losses > 0 else 0.0\n",
        "\n",
        "    # Calculate drawdown: track cumulative PnL after each trade and find the max drawdown\n",
        "    trades_df['cumulative_pnl'] = trades_df['pnl'].cumsum()\n",
        "    peak = trades_df['cumulative_pnl'].cummax()\n",
        "    drawdowns = trades_df['cumulative_pnl'] - peak\n",
        "    max_drawdown = drawdowns.min()\n",
        "\n",
        "    # Total return on capital\n",
        "    if TRADING_MODE == 'capital':\n",
        "        return_on_capital = (total_realized_pnl / Y_CAPITAL) * 100\n",
        "    else:\n",
        "        # Calculate average entry price\n",
        "        avg_entry_price = trades_df['entry_price'].mean()\n",
        "        total_invested = QUANTITY * avg_entry_price\n",
        "        return_on_capital = (total_realized_pnl / total_invested) * 100\n",
        "\n",
        "    # Profit Factor: Gross Profit / Gross Loss\n",
        "    gross_profit = trades_df[trades_df['pnl'] > 0]['pnl'].sum()\n",
        "    gross_loss = abs(trades_df[trades_df['pnl'] < 0]['pnl'].sum())\n",
        "    profit_factor = (gross_profit / gross_loss) if gross_loss != 0 else np.inf\n",
        "\n",
        "    # Calculate net profit (sum of all PnL values)\n",
        "    net_profit = trades_df['pnl'].sum()\n",
        "\n",
        "    # Optional: Sharpe Ratio (requires risk-free rate and return series)\n",
        "    if trades_df['pnl'].std() != 0:\n",
        "        sharpe_ratio = (trades_df['pnl'].mean() / trades_df['pnl'].std()) * np.sqrt(252)  # Annualized\n",
        "    else:\n",
        "        sharpe_ratio = np.nan\n",
        "\n",
        "    # Print Summary\n",
        "    logging.info(\"----- TRADE ANALYTICS REPORT -----\")\n",
        "    logging.info(f\"Total Trades: {total_trades}\")\n",
        "    logging.info(f\"Wins: {wins}, Losses: {losses}\")\n",
        "    logging.info(f\"Win Rate: {win_rate:.2f}%\")\n",
        "    logging.info(f\"Average Win: {avg_win:.2f}, Average Loss: {avg_loss:.2f}\")\n",
        "    logging.info(f\"Gross Profit: {gross_profit:.2f}\")\n",
        "    logging.info(f\"Gross Loss: {gross_loss:.2f}\")\n",
        "    logging.info(f\"Net Profit: {net_profit:.2f}\")\n",
        "    logging.info(f\"Profit Factor: {profit_factor:.2f}\")\n",
        "    logging.info(f\"Total Realized PnL: {total_realized_pnl:.2f}\")\n",
        "    logging.info(f\"Return on Capital Deployed: {return_on_capital:.2f}%\")\n",
        "    logging.info(f\"Max Drawdown: {max_drawdown:.2f}\")\n",
        "    logging.info(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
        "\n",
        "    logging.info(\"Per-Trade Summary:\")\n",
        "    logging.info(trades_df.to_string(index=False))\n",
        "\n",
        "    save_trade_analytics_report(total_trades, wins, losses, win_rate, avg_win, avg_loss, gross_profit, gross_loss, net_profit, profit_factor, total_realized_pnl, return_on_capital, max_drawdown, sharpe_ratio)\n",
        "\n",
        "    # Save to CSV or Excel if desired\n",
        "    if REPORT_FILE:\n",
        "        try:\n",
        "            trades_df.to_csv(REPORT_FILE, index=False)\n",
        "            logging.info(f\"Trade report saved to {REPORT_FILE}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to save trade report: {e}\")\n",
        "\n",
        "    logging.info(\"----- END OF REPORT -----\")\n",
        "\n",
        "\n",
        "# Function to save trade analytics report\n",
        "def save_trade_analytics_report(total_trades, wins, losses, win_rate, avg_win, avg_loss, gross_profit, gross_loss, net_profit, profit_factor, total_realized_pnl, return_on_capital, max_drawdown, sharpe_ratio):\n",
        "    report_content = (\n",
        "        \"----- TRADE ANALYTICS REPORT -----\\n\"\n",
        "        f\"Total Trades: {total_trades}\\n\"\n",
        "        f\"Wins: {wins}, Losses: {losses}\\n\"\n",
        "        f\"Win Rate: {win_rate:.2f}%\\n\"\n",
        "        f\"Average Win: {avg_win:.2f}, Average Loss: {avg_loss:.2f}\\n\"\n",
        "        f\"Gross Profit: {gross_profit:.2f}\\n\"\n",
        "        f\"Gross Loss: {gross_loss:.2f}\\n\"\n",
        "        f\"Net Profit: {net_profit:.2f}\\n\"\n",
        "        f\"Profit Factor: {profit_factor:.2f}\\n\"\n",
        "        f\"Total Realized PnL: {total_realized_pnl:.2f}\\n\"\n",
        "        f\"Return on Capital Deployed: {return_on_capital:.2f}%\\n\"\n",
        "        f\"Max Drawdown: {max_drawdown:.2f}\\n\"\n",
        "        f\"Sharpe Ratio: {sharpe_ratio:.2f}\\n\"\n",
        "    )\n",
        "    try:\n",
        "        with open(REPORT_FILE_TXT, 'w') as report_file:\n",
        "            report_file.write(report_content)\n",
        "        logging.info(f\"Trade analytics report saved to {REPORT_FILE_TXT}.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error saving trade analytics report: {e}\")"
      ],
      "metadata": {
        "id": "jK2jt814VBej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---------------------------------------------\n",
        "# MAIN LOGIC\n",
        "# ---------------------------------------------"
      ],
      "metadata": {
        "id": "dxei72FsOG4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main_loop():\n",
        "    position_active = False\n",
        "    buy_price = None\n",
        "    last_order_id = None\n",
        "    quantity = None\n",
        "    total_realized_pnl = 0.0\n",
        "\n",
        "    if TRADING_MODE in ['capital', 'quantity']:\n",
        "        if paper_data_handler.df.empty:\n",
        "            logging.warning(\"No paper trading data available. Exiting...\")\n",
        "            return\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Advance time at the start of the loop (for each iteration in paper mode)\n",
        "            if TRADING_MODE in ['capital', 'quantity']:\n",
        "                if paper_data_handler.current_index is None or paper_data_handler.current_index >= len(paper_data_handler.df):\n",
        "                    logging.info(\"No more data to simulate. Exiting gracefully...\")\n",
        "                    break\n",
        "\n",
        "            df = get_latest_candles()\n",
        "            if df is None or df.empty:\n",
        "                logging.warning(\"No candle data available. Will try next iteration...\")\n",
        "                if TRADING_MODE in ['capital', 'quantity']:\n",
        "                    if not paper_data_handler.advance_time():\n",
        "                        logging.info(\"No more data available, exiting...\")\n",
        "                        break\n",
        "                time.sleep(CHECK_INTERVAL)\n",
        "                continue\n",
        "\n",
        "            close_prices = df['close']\n",
        "            if len(close_prices) < RSI_PERIOD:\n",
        "                logging.info(\"Not enough data to compute RSI, waiting for more candles...\")\n",
        "                if TRADING_MODE in ['capital', 'quantity']:\n",
        "                    if not paper_data_handler.advance_time():\n",
        "                        logging.info(\"Data ended while waiting for RSI calculation. Exiting...\")\n",
        "                        break\n",
        "                time.sleep(CHECK_INTERVAL)\n",
        "                continue\n",
        "\n",
        "            rsi_series = calculate_rsi(close_prices, period=RSI_PERIOD)\n",
        "            if rsi_series.empty:\n",
        "                logging.warning(\"RSI series empty. Will try next iteration...\")\n",
        "                if TRADING_MODE in ['capital', 'quantity']:\n",
        "                    if not paper_data_handler.advance_time():\n",
        "                        logging.info(\"No more data available, exiting...\")\n",
        "                        break\n",
        "                time.sleep(CHECK_INTERVAL)\n",
        "                continue\n",
        "\n",
        "            current_rsi = rsi_series.iloc[-1]\n",
        "\n",
        "            # Fetch current LTP\n",
        "            ltp = fetch_ltp()\n",
        "            if ltp is None:\n",
        "                logging.warning(\"Failed to fetch LTP. Will retry next iteration...\")\n",
        "                if TRADING_MODE in ['capital', 'quantity']:\n",
        "                    if not paper_data_handler.advance_time():\n",
        "                        logging.info(\"No more data available, exiting...\")\n",
        "                        break\n",
        "                time.sleep(CHECK_INTERVAL)\n",
        "                continue\n",
        "\n",
        "            # Determine quantity based on trading mode\n",
        "            if quantity is None:\n",
        "                if TRADING_MODE == 'capital':\n",
        "                    quantity = math.floor(Y_CAPITAL / ltp)\n",
        "                    if quantity <= 0:\n",
        "                        logging.error(\"Capital not sufficient to buy even 1 share.\")\n",
        "                        break\n",
        "                elif TRADING_MODE == 'quantity':\n",
        "                    quantity = QUANTITY\n",
        "                    if quantity <= 0:\n",
        "                        logging.error(\"QUANTITY must be a positive integer.\")\n",
        "                        break\n",
        "\n",
        "            logging.info(f\"LTP: {ltp}, RSI: {current_rsi}, Position: {position_active}, Buy_Price: {buy_price}, Quantity: {quantity}\")\n",
        "\n",
        "            # Entry Condition\n",
        "            if not position_active:\n",
        "                if current_rsi <= RSI_BUY_THRESHOLD:\n",
        "                    order_id = place_order(\"BUY\", quantity)\n",
        "                    if order_id:\n",
        "                        position_active = True\n",
        "                        buy_price = ltp\n",
        "                        last_order_id = order_id\n",
        "                        logging.info(f\"Bought at {buy_price}, Qty: {quantity}\")\n",
        "\n",
        "            else:\n",
        "                # Position active - check exit conditions\n",
        "                profit_per_share = ltp - buy_price\n",
        "                if profit_per_share >= X_PROFIT or current_rsi >= RSI_SELL_THRESHOLD or profit_per_share <= -STOP_LOSS:\n",
        "                    order_id = place_order(\"SELL\", quantity)\n",
        "                    if order_id:\n",
        "                        position_active = False\n",
        "                        realized_pnl = profit_per_share * quantity\n",
        "                        total_realized_pnl += realized_pnl\n",
        "                        logging.info(f\"Sold at {ltp}, Profit/Share: {profit_per_share}, Total Realized PnL: {total_realized_pnl}\")\n",
        "\n",
        "                        # Record the trade for analytics\n",
        "                        trades.append({\n",
        "                            'entry_price': buy_price,\n",
        "                            'exit_price': ltp,\n",
        "                            'profit_per_share': profit_per_share,\n",
        "                            'quantity': quantity,\n",
        "                            'pnl': realized_pnl,\n",
        "                            'time': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                        })\n",
        "\n",
        "                        buy_price = None\n",
        "                        last_order_id = None\n",
        "\n",
        "            # Advance time in paper trading mode\n",
        "            if TRADING_MODE in ['capital', 'quantity']:\n",
        "                if not paper_data_handler.advance_time():\n",
        "                    logging.info(\"No more data to simulate. Exiting gracefully...\")\n",
        "                    break\n",
        "\n",
        "            time.sleep(CHECK_INTERVAL)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            logging.info(\"Exiting gracefully due to keyboard interrupt.\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in main loop: {e}\")\n",
        "            time.sleep(CHECK_INTERVAL)\n",
        "\n",
        "    logging.info(f\"Exiting strategy. Total Realized PnL: {total_realized_pnl}\")\n",
        "    generate_trade_report(trades, total_realized_pnl)"
      ],
      "metadata": {
        "id": "g_9ISkPiOHmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_loop()"
      ],
      "metadata": {
        "id": "FNs8Qm9zOOK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "def fetch_stock_data_in_chunks(symbol, start_date, end_date, interval=\"1m\", output_csv=\"stock_data.csv\"):\n",
        "    \"\"\"\n",
        "    Fetches historical stock data in chunks to handle limitations of Yahoo Finance API for '1m' interval.\n",
        "    Args:\n",
        "        symbol (str): Stock symbol (e.g., \"AAPL\").\n",
        "        start_date (str): Start date in \"YYYY-MM-DD\" format.\n",
        "        end_date (str): End date in \"YYYY-MM-DD\" format.\n",
        "        interval (str): Data interval (e.g., \"1m\", \"5m\").\n",
        "        output_csv (str): Output CSV file name.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        start = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "        end = datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "\n",
        "        all_data = []\n",
        "\n",
        "        logging.info(f\"Fetching {interval} data for {symbol} from {start_date} to {end_date}...\")\n",
        "\n",
        "        while start < end:\n",
        "            chunk_end = start + datetime.timedelta(days=7)  # Yahoo allows up to 7 days for '1m' interval\n",
        "            if chunk_end > end:\n",
        "                chunk_end = end\n",
        "\n",
        "            logging.info(f\"Fetching data for {symbol} from {start.strftime('%Y-%m-%d')} to {chunk_end.strftime('%Y-%m-%d')}...\")\n",
        "            data = yf.download(tickers=symbol, start=start.strftime('%Y-%m-%d'), end=chunk_end.strftime('%Y-%m-%d'), interval=interval)\n",
        "\n",
        "            if not data.empty:\n",
        "                # Rename the Datetime index to 'date' and reset index\n",
        "                data = data.rename_axis('date').reset_index()\n",
        "\n",
        "                # Rename columns to match desired output\n",
        "                rename_map = {\n",
        "                    'date': 'date',\n",
        "                    'High': 'high',\n",
        "                    'Close': 'close',\n",
        "                    'Low': 'low',\n",
        "                    'Open': 'open',\n",
        "                    'Volume': 'volume'\n",
        "                }\n",
        "                # Map only the desired columns\n",
        "                data = data[['date', 'High', 'Close', 'Low', 'Open', 'Volume']].rename(columns=rename_map)\n",
        "\n",
        "                all_data.append(data)\n",
        "                logging.info(f\"Data fetched for {symbol} from {start.strftime('%Y-%m-%d')} to {chunk_end.strftime('%Y-%m-%d')} ({len(data)} rows).\")\n",
        "            else:\n",
        "                logging.warning(f\"No data found for {symbol} from {start.strftime('%Y-%m-%d')} to {chunk_end.strftime('%Y-%m-%d')}.\")\n",
        "\n",
        "            # Move start to the next day after the current chunk\n",
        "            start = chunk_end\n",
        "\n",
        "        # Combine all chunks into one DataFrame\n",
        "        if all_data:\n",
        "            combined_data = pd.concat(all_data)\n",
        "            combined_data.reset_index(drop=True, inplace=True)  # Ensure clean index for the final DataFrame\n",
        "\n",
        "            # Drop the first row\n",
        "            combined_data = combined_data.iloc[1:]\n",
        "\n",
        "            # Save to CSV\n",
        "            logging.info(f\"Saving combined data to {output_csv}...\")\n",
        "            combined_data.to_csv(output_csv, index=False)\n",
        "            logging.info(f\"Data saved successfully to {output_csv}.\")\n",
        "        else:\n",
        "            logging.warning(\"No data fetched for the entire range.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error fetching stock data for {symbol}: {e}\", exc_info=True)\n",
        "\n",
        "# Example usage\n",
        "# fetch_stock_data_in_chunks(\"SBIN.NS\", \"2024-01-01\", \"2024-12-31\", interval=\"1m\", output_csv=\"sbin.csv\")"
      ],
      "metadata": {
        "id": "J0W1EnjZtNv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "RSI_PERIOD = 15\n",
        "SUPER_TREND_MULTIPLIER = 3\n",
        "SUPER_TREND_PERIOD = 10\n",
        "\n",
        "# Load and preprocess data\n",
        "df = pd.read_csv(CSV_FILE)\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "# Function to calculate RSI\n",
        "def calculate_rsi(series, period=14):\n",
        "    delta = series.diff()\n",
        "    gain = delta.where(delta > 0, 0.0)\n",
        "    loss = -delta.where(delta < 0, 0.0)\n",
        "    avg_gain = gain.rolling(window=period, min_periods=1).mean()\n",
        "    avg_loss = loss.rolling(window=period, min_periods=1).mean()\n",
        "    rs = avg_gain / avg_loss\n",
        "    rsi = 100.0 - (100.0 / (1.0 + rs))\n",
        "    return rsi\n",
        "\n",
        "# Function to calculate Supertrend\n",
        "def calculate_supertrend(df, period=10, multiplier=3):\n",
        "    \"\"\"\n",
        "    Calculates the Supertrend indicator.\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame with 'high', 'low', 'close' columns.\n",
        "        period (int): ATR period.\n",
        "        multiplier (float): Multiplier for ATR bands.\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with 'supertrend', 'upper_band', 'lower_band', and 'trend'.\n",
        "    \"\"\"\n",
        "    # Calculate Average True Range (ATR)\n",
        "    hl2 = (df['high'] + df['low']) / 2\n",
        "    df['atr'] = df['high'].combine(df['low'], max) - df['low'].combine(df['close'], min)\n",
        "    df['atr'] = df['atr'].rolling(window=period).mean()\n",
        "\n",
        "    # Calculate upper and lower bands\n",
        "    df['upper_band'] = hl2 + (multiplier * df['atr'])\n",
        "    df['lower_band'] = hl2 - (multiplier * df['atr'])\n",
        "    df['supertrend'] = np.nan  # Initialize supertrend column\n",
        "\n",
        "    # Initialize trend variable\n",
        "    in_uptrend = True\n",
        "\n",
        "    # Iteratively calculate Supertrend\n",
        "    for i in range(1, len(df)):\n",
        "        if df['close'].iloc[i] > df['upper_band'].iloc[i - 1]:\n",
        "            in_uptrend = True\n",
        "        elif df['close'].iloc[i] < df['lower_band'].iloc[i - 1]:\n",
        "            in_uptrend = False\n",
        "\n",
        "        # Update supertrend based on the trend direction\n",
        "        if in_uptrend:\n",
        "            df.loc[i, 'supertrend'] = df['lower_band'].iloc[i]\n",
        "        else:\n",
        "            df.loc[i, 'supertrend'] = df['upper_band'].iloc[i]\n",
        "\n",
        "    # Identify trend direction\n",
        "    df['trend'] = np.where(df['close'] > df['supertrend'], 'up', 'down')\n",
        "\n",
        "    # Clean up intermediate columns\n",
        "    df.drop(['atr'], axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "# Calculate indicators\n",
        "df['rsi'] = calculate_rsi(df['close'], RSI_PERIOD)\n",
        "df = calculate_supertrend(df, period=SUPER_TREND_PERIOD, multiplier=SUPER_TREND_MULTIPLIER)\n",
        "\n",
        "# Define Buy and Sell signals\n",
        "df['buy_signal'] = np.where((df['trend'] == 'up') & (df['rsi'] < 30), df['close'], np.nan)\n",
        "df['sell_signal'] = np.where((df['trend'] == 'down') & (df['rsi'] > 70), df['close'], np.nan)\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(14, 10))\n",
        "\n",
        "# Price and Supertrend Plot\n",
        "plt.plot(df['date'], df['close'], label='Close Price', color='blue')\n",
        "plt.plot(df['date'], df['supertrend'], label='Supertrend', color='green')\n",
        "\n",
        "# Buy/Sell signals\n",
        "plt.scatter(df['date'], df['buy_signal'], label='Buy Signal', color='green', marker='^', s=100, zorder=5)\n",
        "plt.scatter(df['date'], df['sell_signal'], label='Sell Signal', color='red', marker='v', s=100, zorder=5)\n",
        "\n",
        "plt.title('Price with Supertrend and Buy/Sell Signals')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "# RSI Plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(df['date'], df['rsi'], label='RSI', color='orange')\n",
        "plt.axhline(70, color='red', linestyle='--', label='Overbought (70)')\n",
        "plt.axhline(30, color='green', linestyle='--', label='Oversold (30)')\n",
        "\n",
        "plt.scatter(df['date'], df['rsi'], c=np.where(df['rsi'] < 30, 'green', np.where(df['rsi'] > 70, 'red', 'orange')), label='RSI Signal', s=10)\n",
        "\n",
        "plt.title('RSI with Buy/Sell Signals')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(\"sbin_with_signals.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "XGQPXZz-1r5t",
        "outputId": "f93037a9-bc04-406f-979f-d014fb14df82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'date'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-ea1d65ac2fb8>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load and preprocess data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'"
          ]
        }
      ]
    }
  ]
}