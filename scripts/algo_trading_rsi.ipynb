{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q-yRfc1HaNKc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (2.2.0)\n",
            "Requirement already satisfied: matplotlib in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (3.10.0)\n",
            "Requirement already satisfied: yfinance in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (0.2.50)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: requests>=2.31 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from yfinance) (5.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from yfinance) (3.17.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: six>=1.9 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from html5lib>=1.1->yfinance) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from requests>=2.31->yfinance) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy matplotlib yfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_XZICm1wMfnp"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import logging\n",
        "# from kiteconnect import KiteConnect\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWjAlJ6pNqpL"
      },
      "source": [
        "# ---------------------------------------------\n",
        "# CONFIGURATIONS & USER INPUTS\n",
        "# ---------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtUFywGKNH98"
      },
      "outputs": [],
      "source": [
        "# Trading Mode: 'capital' or 'quantity'\n",
        "TRADING_MODE = 'quantity'  # Change to 'capital' for capital-based trading\n",
        "\n",
        "# Parameters for Capital-Based Trading\n",
        "Y_CAPITAL = 100000.0          # Total capital dedicated to this strategy in INR\n",
        "\n",
        "# Parameters for Quantity-Based Trading\n",
        "QUANTITY = 1000                 # Fixed number of shares to trade\n",
        "\n",
        "# Common Strategy Parameters\n",
        "INSTRUMENT = \"NSE:SBIN\"\n",
        "X_PROFIT = 2.0\n",
        "RSI_PERIOD = 14\n",
        "SUPER_TREND_PERIOD = 10\n",
        "SUPER_TREND_MULTIPLIER = 3\n",
        "TIMEFRAME = \"5minute\"\n",
        "RSI_BUY_THRESHOLD = 30 #make a range here\n",
        "RSI_SELL_THRESHOLD = 60\n",
        "STOP_LOSS = 10.0\n",
        "CHECK_INTERVAL = 0\n",
        "\n",
        "# CSV with historical data for paper trading\n",
        "CSV_FILE = \"sbin_ns.csv\"     # Replace with your actual historical data file\n",
        "\n",
        "# Output report file\n",
        "REPORT_FILE_TXT = \"trade_report.txt\"\n",
        "REPORT_FILE = \"trade_report.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJk7dlpiNu8v"
      },
      "source": [
        "# ---------------------------------------------\n",
        "# LOGGING CONFIG\n",
        "# ---------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOM4D46ANyek"
      },
      "outputs": [],
      "source": [
        "# logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s]: %(message)s')\n",
        "# Configure logging\n",
        "logging.basicConfig(filename='app.log',\n",
        "                    level=logging.DEBUG,\n",
        "                    force=True, # Resets any previous configuration\n",
        "                    )\n",
        "\n",
        "logging.info(\"Logging is set up and ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iry2xb4MPd_D"
      },
      "source": [
        "# ---------------------------------------------\n",
        "# KITE CONNECT SETUP\n",
        "# ---------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8D08-_aPeqO"
      },
      "outputs": [],
      "source": [
        "kite = None\n",
        "if TRADING_MODE == 'capital' or TRADING_MODE == 'quantity':\n",
        "    # Assuming live trading requires Kite API credentials\n",
        "    # For paper trading, these are not required\n",
        "    pass\n",
        "\n",
        "# For live trading, uncomment and set your API credentials\n",
        "# API_KEY = \"your_api_key_here\"\n",
        "# API_SECRET = \"your_api_secret_here\"\n",
        "# ACCESS_TOKEN = \"your_access_token_here\"\n",
        "\n",
        "# Uncomment the following block for live trading setup\n",
        "# if TRADING_MODE == 'live':\n",
        "#     if not API_KEY or not API_SECRET or not ACCESS_TOKEN:\n",
        "#         logging.error(\"API_KEY, API_SECRET, ACCESS_TOKEN must be set for live trading!\")\n",
        "#         raise ValueError(\"Invalid API keys or tokens for live trading.\")\n",
        "#\n",
        "#     kite = KiteConnect(api_key=API_KEY)\n",
        "#     kite.set_access_token(ACCESS_TOKEN)\n",
        "#     # Test the connection\n",
        "#     try:\n",
        "#         profile = kite.profile()\n",
        "#         logging.info(f\"Successfully authenticated with Zerodha. User: {profile['user_name']}\")\n",
        "#     except Exception as e:\n",
        "#         logging.error(f\"Failed to authenticate with Zerodha: {e}\")\n",
        "#         raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am4L15fjPkcu"
      },
      "source": [
        "# ---------------------------------------------\n",
        "# PAPER DATA HANDLER (For Paper Trading)\n",
        "# ---------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzS1XUtOPlIy"
      },
      "outputs": [],
      "source": [
        "class PaperDataHandler:\n",
        "    \"\"\"\n",
        "    Simulates fetching of historical and 'live' data from a local CSV for paper trading.\n",
        "    - Loads a CSV with OHLC data.\n",
        "    - Provides methods to get the latest candle slice for RSI calculation.\n",
        "    - Provides a method to get the current LTP (simulated as the close of the latest candle).\n",
        "    - Advances a pointer through the CSV rows to simulate time passing.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, csv_file):\n",
        "        self.csv_file = csv_file\n",
        "        self.df = None\n",
        "        self.current_index = None\n",
        "        self.load_data()\n",
        "\n",
        "    def load_data(self):\n",
        "      if not os.path.exists(self.csv_file):\n",
        "          logging.error(f\"CSV file {self.csv_file} not found. Exiting gracefully...\")\n",
        "          self.df = pd.DataFrame()\n",
        "          return\n",
        "\n",
        "      self.df = pd.read_csv(self.csv_file)\n",
        "\n",
        "      # Convert column names to lowercase\n",
        "      self.df.columns = map(str.lower, self.df.columns)\n",
        "\n",
        "      # Validate data\n",
        "      required_cols = {'date', 'open', 'high', 'low', 'close', 'volume'}\n",
        "      if not required_cols.issubset(set(self.df.columns)):\n",
        "          logging.error(f\"CSV file {self.csv_file} does not have the required columns: {required_cols}\")\n",
        "          self.df = pd.DataFrame()\n",
        "          return\n",
        "\n",
        "      # Handle date parsing with error handling\n",
        "      try:\n",
        "          self.df['date'] = pd.to_datetime(self.df['date'], dayfirst=True, errors='coerce')\n",
        "      except Exception as e:\n",
        "          logging.error(f\"Error parsing dates: {e}\")\n",
        "          self.df = pd.DataFrame()\n",
        "          return\n",
        "\n",
        "      # Drop rows where date parsing failed\n",
        "      if self.df['date'].isnull().any():\n",
        "          logging.warning(f\"Some rows have invalid date formats and will be dropped.\")\n",
        "          self.df = self.df.dropna(subset=['date'])\n",
        "\n",
        "      # Sort by date if not sorted\n",
        "      self.df = self.df.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "      if self.df.empty:\n",
        "          logging.error(\"CSV data is empty after processing. Exiting...\")\n",
        "          return\n",
        "\n",
        "      # Start from the RSI_PERIOD-th candle to have enough data for RSI calculation\n",
        "      self.current_index = RSI_PERIOD\n",
        "\n",
        "    def get_historical_candles(self, lookback=100):\n",
        "        \"\"\"\n",
        "        Returns a historical slice of candles up to current_index for RSI calculation.\n",
        "        If current_index is None or data insufficient, return empty df.\n",
        "        \"\"\"\n",
        "        if self.df.empty or self.current_index is None:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        start_idx = max(0, self.current_index - lookback)\n",
        "        return self.df.iloc[start_idx:self.current_index]\n",
        "\n",
        "    def get_current_ltp(self):\n",
        "        \"\"\"\n",
        "        Returns the current candle's close price as LTP.\n",
        "        If no more data is available, return None.\n",
        "        \"\"\"\n",
        "        if self.df.empty or self.current_index is None:\n",
        "            return None\n",
        "        if self.current_index >= len(self.df):\n",
        "            return None\n",
        "        return self.df.iloc[self.current_index]['close']\n",
        "\n",
        "    def advance_time(self):\n",
        "        \"\"\"\n",
        "        Move to the next candle, simulating passing of time.\n",
        "        If no more data, return False to indicate we are done.\n",
        "        \"\"\"\n",
        "        if self.df.empty or self.current_index is None:\n",
        "            return False\n",
        "        self.current_index += 1\n",
        "        if self.current_index >= len(self.df):\n",
        "            # No more data available\n",
        "            return False\n",
        "        return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WimG3ivPwOg"
      },
      "source": [
        "# Initialize PaperDataHandler if PAPER_TRADING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOMzrCKbPxI_",
        "outputId": "73f25568-a8a5-4446-8cf4-2ea78ba2ab16"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-26-c9a76506c313>:36: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S%z format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
            "  self.df['date'] = pd.to_datetime(self.df['date'], dayfirst=True, errors='coerce')\n"
          ]
        }
      ],
      "source": [
        "paper_data_handler = None\n",
        "if TRADING_MODE in ['capital', 'quantity']:\n",
        "    paper_data_handler = PaperDataHandler(CSV_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk55him9N1n1"
      },
      "source": [
        "# ---------------------------------------------\n",
        "# VALIDATIONS\n",
        "# ---------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuIJIc_pN3-a"
      },
      "outputs": [],
      "source": [
        "if TRADING_MODE not in ['capital', 'quantity']:\n",
        "    logging.error(\"Invalid TRADING_MODE. Choose 'capital' or 'quantity'.\")\n",
        "    raise ValueError(\"Invalid TRADING_MODE. Choose 'capital' or 'quantity'.\")\n",
        "\n",
        "if TRADING_MODE == 'capital' and Y_CAPITAL <= 0:\n",
        "    logging.error(\"Y_CAPITAL must be a positive number for capital-based trading.\")\n",
        "    raise ValueError(\"Invalid Y_CAPITAL for capital-based trading.\")\n",
        "\n",
        "if TRADING_MODE == 'quantity' and (not isinstance(QUANTITY, int) or QUANTITY <= 0):\n",
        "    logging.error(\"QUANTITY must be a positive integer for quantity-based trading.\")\n",
        "    raise ValueError(\"Invalid QUANTITY for quantity-based trading.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "224xMRqWN8RV"
      },
      "source": [
        "# ---------------------------------------------\n",
        "# HELPER FUNCTIONS\n",
        "# ---------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly0AVgPbN6M9"
      },
      "outputs": [],
      "source": [
        "def calculate_rsi(series, period=14):\n",
        "    \"\"\"\n",
        "    Calculate RSI for the given price series.\n",
        "    \"\"\"\n",
        "    delta = series.diff().dropna()\n",
        "    up = delta.where(delta > 0, 0.0)\n",
        "    down = -delta.where(delta < 0, 0.0)\n",
        "    gain = up.rolling(window=period, min_periods=1).mean()\n",
        "    loss = down.rolling(window=period, min_periods=1).mean()\n",
        "    RS = gain / loss\n",
        "    RSI = 100.0 - (100.0 / (1.0 + RS))\n",
        "    return RSI\n",
        "\n",
        "def get_latest_candles():\n",
        "    \"\"\"\n",
        "    Fetch historical data for RSI calculation:\n",
        "    - In paper mode, fetch from the PaperDataHandler.\n",
        "    - In live mode, fetch from Zerodha (not implemented here).\n",
        "    \"\"\"\n",
        "    if TRADING_MODE in ['capital', 'quantity']:\n",
        "        df = paper_data_handler.get_historical_candles()\n",
        "        return df\n",
        "    else:\n",
        "        # Implement live mode historical fetch if needed\n",
        "        return None\n",
        "\n",
        "def fetch_ltp():\n",
        "    \"\"\"\n",
        "    Get the current LTP.\n",
        "    - In paper mode, from PaperDataHandler.\n",
        "    - In live mode, from kite.ltp.\n",
        "    \"\"\"\n",
        "    if TRADING_MODE in ['capital', 'quantity']:\n",
        "        ltp = paper_data_handler.get_current_ltp()\n",
        "        return ltp\n",
        "    else:\n",
        "        try:\n",
        "            data = kite.ltp(INSTRUMENT)\n",
        "            return data[INSTRUMENT]['last_price']\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error fetching LTP: {e}\")\n",
        "            return None\n",
        "\n",
        "def place_order(transaction_type, quantity, price=None):\n",
        "    \"\"\"\n",
        "    Simulate or place a market order.\n",
        "    \"\"\"\n",
        "    if TRADING_MODE in ['capital', 'quantity']:\n",
        "        # Paper Trading: Simulate order\n",
        "        mock_order_id = f\"mock_{transaction_type}_{int(time.time())}\"\n",
        "        logging.info(f\"(Paper Trade) Order Placed: {transaction_type} Qty: {quantity}, ID: {mock_order_id}\")\n",
        "        return mock_order_id\n",
        "    else:\n",
        "        # Live Trading: Place order via Kite API\n",
        "        try:\n",
        "            order_id = kite.place_order(\n",
        "                variety=kite.VARIETY_REGULAR,\n",
        "                exchange=\"NSE\",\n",
        "                tradingsymbol=INSTRUMENT.split(':')[-1],\n",
        "                transaction_type=transaction_type,\n",
        "                quantity=quantity,\n",
        "                order_type=kite.ORDER_TYPE_MARKET,\n",
        "                product=kite.PRODUCT_MIS\n",
        "            )\n",
        "            logging.info(f\"Order placed. Type: {transaction_type}, Qty: {quantity}, ID: {order_id}\")\n",
        "            return order_id\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Order placement failed: {e}\")\n",
        "            return None\n",
        "\n",
        "def calculate_supertrend(df, period=10, multiplier=3):\n",
        "    hl2 = (df['high'] + df['low']) / 2\n",
        "    atr = (df['high'] - df['low']).rolling(window=period).mean()\n",
        "    upper_band = hl2 + (multiplier * atr)\n",
        "    lower_band = hl2 - (multiplier * atr)\n",
        "    df['supertrend'] = np.nan\n",
        "    in_uptrend = True\n",
        "    for i in range(1, len(df)):\n",
        "        if df['close'].iloc[i] > upper_band.iloc[i - 1]:\n",
        "            in_uptrend = True\n",
        "        elif df['close'].iloc[i] < lower_band.iloc[i - 1]:\n",
        "            in_uptrend = False\n",
        "        df.loc[i, 'supertrend'] = lower_band.iloc[i] if in_uptrend else upper_band.iloc[i]\n",
        "    df['trend'] = np.where(df['close'] > df['supertrend'], 'up', 'down')\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOsg1VFiU28R"
      },
      "source": [
        "# ---------------------------------------------\n",
        "# TRADE ANALYTICS\n",
        "# ---------------------------------------------\n",
        "# We'll store each completed trade in a list of dicts for analysis at the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9X2CgFckU35j"
      },
      "outputs": [],
      "source": [
        "trades = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uq8lD-KVCz0"
      },
      "source": [
        "# ---------------------------------------------\n",
        "# TRADE ANALYTICS & REPORTING\n",
        "# ---------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jK2jt814VBej"
      },
      "outputs": [],
      "source": [
        "def generate_trade_report(trades, total_realized_pnl):\n",
        "    if not trades:\n",
        "        logging.info(\"No trades were executed. No analytics available.\")\n",
        "        return\n",
        "\n",
        "    # Convert to DataFrame for easier analysis\n",
        "    trades_df = pd.DataFrame(trades)\n",
        "\n",
        "    total_trades = len(trades_df)\n",
        "    wins = trades_df[trades_df['pnl'] > 0].shape[0]\n",
        "    losses = trades_df[trades_df['pnl'] < 0].shape[0]\n",
        "    win_rate = (wins / total_trades) * 100 if total_trades > 0 else 0.0\n",
        "    avg_win = trades_df[trades_df['pnl'] > 0]['pnl'].mean() if wins > 0 else 0.0\n",
        "    avg_loss = trades_df[trades_df['pnl'] < 0]['pnl'].mean() if losses > 0 else 0.0\n",
        "\n",
        "    # Calculate drawdown: track cumulative PnL after each trade and find the max drawdown\n",
        "    trades_df['cumulative_pnl'] = trades_df['pnl'].cumsum()\n",
        "    peak = trades_df['cumulative_pnl'].cummax()\n",
        "    drawdowns = trades_df['cumulative_pnl'] - peak\n",
        "    max_drawdown = drawdowns.min()\n",
        "\n",
        "    # Total return on capital\n",
        "    if TRADING_MODE == 'capital':\n",
        "        return_on_capital = (total_realized_pnl / Y_CAPITAL) * 100\n",
        "    else:\n",
        "        # Calculate average entry price\n",
        "        avg_entry_price = trades_df['entry_price'].mean()\n",
        "        total_invested = QUANTITY * avg_entry_price\n",
        "        return_on_capital = (total_realized_pnl / total_invested) * 100\n",
        "\n",
        "    # Profit Factor: Gross Profit / Gross Loss\n",
        "    gross_profit = trades_df[trades_df['pnl'] > 0]['pnl'].sum()\n",
        "    gross_loss = abs(trades_df[trades_df['pnl'] < 0]['pnl'].sum())\n",
        "    profit_factor = (gross_profit / gross_loss) if gross_loss != 0 else np.inf\n",
        "\n",
        "    # Calculate net profit (sum of all PnL values)\n",
        "    net_profit = trades_df['pnl'].sum()\n",
        "\n",
        "    # Optional: Sharpe Ratio (requires risk-free rate and return series)\n",
        "    if trades_df['pnl'].std() != 0:\n",
        "        sharpe_ratio = (trades_df['pnl'].mean() / trades_df['pnl'].std()) * np.sqrt(252)  # Annualized\n",
        "    else:\n",
        "        sharpe_ratio = np.nan\n",
        "\n",
        "    # Print Summary\n",
        "    logging.info(\"----- TRADE ANALYTICS REPORT -----\")\n",
        "    logging.info(f\"Total Trades: {total_trades}\")\n",
        "    logging.info(f\"Wins: {wins}, Losses: {losses}\")\n",
        "    logging.info(f\"Win Rate: {win_rate:.2f}%\")\n",
        "    logging.info(f\"Average Win: {avg_win:.2f}, Average Loss: {avg_loss:.2f}\")\n",
        "    logging.info(f\"Gross Profit: {gross_profit:.2f}\")\n",
        "    logging.info(f\"Gross Loss: {gross_loss:.2f}\")\n",
        "    logging.info(f\"Net Profit: {net_profit:.2f}\")\n",
        "    logging.info(f\"Profit Factor: {profit_factor:.2f}\")\n",
        "    logging.info(f\"Total Realized PnL: {total_realized_pnl:.2f}\")\n",
        "    logging.info(f\"Return on Capital Deployed: {return_on_capital:.2f}%\")\n",
        "    logging.info(f\"Max Drawdown: {max_drawdown:.2f}\")\n",
        "    logging.info(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
        "\n",
        "    logging.info(\"Per-Trade Summary:\")\n",
        "    logging.info(trades_df.to_string(index=False))\n",
        "\n",
        "    save_trade_analytics_report(total_trades, wins, losses, win_rate, avg_win, avg_loss, gross_profit, gross_loss, net_profit, profit_factor, total_realized_pnl, return_on_capital, max_drawdown, sharpe_ratio)\n",
        "\n",
        "    # Save to CSV or Excel if desired\n",
        "    if REPORT_FILE:\n",
        "        try:\n",
        "            trades_df.to_csv(REPORT_FILE, index=False)\n",
        "            logging.info(f\"Trade report saved to {REPORT_FILE}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to save trade report: {e}\")\n",
        "\n",
        "    logging.info(\"----- END OF REPORT -----\")\n",
        "\n",
        "\n",
        "# Function to save trade analytics report\n",
        "def save_trade_analytics_report(total_trades, wins, losses, win_rate, avg_win, avg_loss, gross_profit, gross_loss, net_profit, profit_factor, total_realized_pnl, return_on_capital, max_drawdown, sharpe_ratio):\n",
        "    report_content = (\n",
        "        \"----- TRADE ANALYTICS REPORT -----\\n\"\n",
        "        f\"Total Trades: {total_trades}\\n\"\n",
        "        f\"Wins: {wins}, Losses: {losses}\\n\"\n",
        "        f\"Win Rate: {win_rate:.2f}%\\n\"\n",
        "        f\"Average Win: {avg_win:.2f}, Average Loss: {avg_loss:.2f}\\n\"\n",
        "        f\"Gross Profit: {gross_profit:.2f}\\n\"\n",
        "        f\"Gross Loss: {gross_loss:.2f}\\n\"\n",
        "        f\"Net Profit: {net_profit:.2f}\\n\"\n",
        "        f\"Profit Factor: {profit_factor:.2f}\\n\"\n",
        "        f\"Total Realized PnL: {total_realized_pnl:.2f}\\n\"\n",
        "        f\"Return on Capital Deployed: {return_on_capital:.2f}%\\n\"\n",
        "        f\"Max Drawdown: {max_drawdown:.2f}\\n\"\n",
        "        f\"Sharpe Ratio: {sharpe_ratio:.2f}\\n\"\n",
        "    )\n",
        "    try:\n",
        "        with open(REPORT_FILE_TXT, 'w') as report_file:\n",
        "            report_file.write(report_content)\n",
        "        logging.info(f\"Trade analytics report saved to {REPORT_FILE_TXT}.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error saving trade analytics report: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxei72FsOG4t"
      },
      "source": [
        "# ---------------------------------------------\n",
        "# MAIN LOGIC\n",
        "# ---------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_9ISkPiOHmZ"
      },
      "outputs": [],
      "source": [
        "def main_loop():\n",
        "    position_active = False\n",
        "    buy_price = None\n",
        "    last_order_id = None\n",
        "    quantity = None\n",
        "    total_realized_pnl = 0.0\n",
        "\n",
        "    if TRADING_MODE in ['capital', 'quantity']:\n",
        "        if paper_data_handler.df.empty:\n",
        "            logging.warning(\"No paper trading data available. Exiting...\")\n",
        "            return\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Advance time at the start of the loop (for each iteration in paper mode)\n",
        "            if TRADING_MODE in ['capital', 'quantity']:\n",
        "                if paper_data_handler.current_index is None or paper_data_handler.current_index >= len(paper_data_handler.df):\n",
        "                    logging.info(\"No more data to simulate. Exiting gracefully...\")\n",
        "                    break\n",
        "\n",
        "            df = get_latest_candles()\n",
        "            if df is None or df.empty:\n",
        "                logging.warning(\"No candle data available. Will try next iteration...\")\n",
        "                if TRADING_MODE in ['capital', 'quantity']:\n",
        "                    if not paper_data_handler.advance_time():\n",
        "                        logging.info(\"No more data available, exiting...\")\n",
        "                        break\n",
        "                time.sleep(CHECK_INTERVAL)\n",
        "                continue\n",
        "\n",
        "            close_prices = df['close']\n",
        "            if len(close_prices) < RSI_PERIOD:\n",
        "                logging.info(\"Not enough data to compute RSI, waiting for more candles...\")\n",
        "                if TRADING_MODE in ['capital', 'quantity']:\n",
        "                    if not paper_data_handler.advance_time():\n",
        "                        logging.info(\"Data ended while waiting for RSI calculation. Exiting...\")\n",
        "                        break\n",
        "                time.sleep(CHECK_INTERVAL)\n",
        "                continue\n",
        "\n",
        "            rsi_series = calculate_rsi(close_prices, period=RSI_PERIOD)\n",
        "            if rsi_series.empty:\n",
        "                logging.warning(\"RSI series empty. Will try next iteration...\")\n",
        "                if TRADING_MODE in ['capital', 'quantity']:\n",
        "                    if not paper_data_handler.advance_time():\n",
        "                        logging.info(\"No more data available, exiting...\")\n",
        "                        break\n",
        "                time.sleep(CHECK_INTERVAL)\n",
        "                continue\n",
        "\n",
        "            current_rsi = rsi_series.iloc[-1]\n",
        "\n",
        "            # Fetch current LTP\n",
        "            ltp = fetch_ltp()\n",
        "            if ltp is None:\n",
        "                logging.warning(\"Failed to fetch LTP. Will retry next iteration...\")\n",
        "                if TRADING_MODE in ['capital', 'quantity']:\n",
        "                    if not paper_data_handler.advance_time():\n",
        "                        logging.info(\"No more data available, exiting...\")\n",
        "                        break\n",
        "                time.sleep(CHECK_INTERVAL)\n",
        "                continue\n",
        "\n",
        "            # Determine quantity based on trading mode\n",
        "            if quantity is None:\n",
        "                if TRADING_MODE == 'capital':\n",
        "                    quantity = math.floor(Y_CAPITAL / ltp)\n",
        "                    if quantity <= 0:\n",
        "                        logging.error(\"Capital not sufficient to buy even 1 share.\")\n",
        "                        break\n",
        "                elif TRADING_MODE == 'quantity':\n",
        "                    quantity = QUANTITY\n",
        "                    if quantity <= 0:\n",
        "                        logging.error(\"QUANTITY must be a positive integer.\")\n",
        "                        break\n",
        "\n",
        "            logging.info(f\"LTP: {ltp}, RSI: {current_rsi}, Position: {position_active}, Buy_Price: {buy_price}, Quantity: {quantity}\")\n",
        "\n",
        "            # Entry Condition\n",
        "            if not position_active:\n",
        "                if current_rsi <= RSI_BUY_THRESHOLD:\n",
        "                    order_id = place_order(\"BUY\", quantity)\n",
        "                    if order_id:\n",
        "                        position_active = True\n",
        "                        buy_price = ltp\n",
        "                        last_order_id = order_id\n",
        "                        logging.info(f\"Bought at {buy_price}, Qty: {quantity}\")\n",
        "\n",
        "            else:\n",
        "                # Position active - check exit conditions\n",
        "                profit_per_share = ltp - buy_price\n",
        "                if profit_per_share >= X_PROFIT or current_rsi >= RSI_SELL_THRESHOLD or profit_per_share <= -STOP_LOSS:\n",
        "                    order_id = place_order(\"SELL\", quantity)\n",
        "                    if order_id:\n",
        "                        position_active = False\n",
        "                        realized_pnl = profit_per_share * quantity\n",
        "                        total_realized_pnl += realized_pnl\n",
        "                        logging.info(f\"Sold at {ltp}, Profit/Share: {profit_per_share}, Total Realized PnL: {total_realized_pnl}\")\n",
        "\n",
        "                        # Record the trade for analytics\n",
        "                        trades.append({\n",
        "                            'entry_price': buy_price,\n",
        "                            'exit_price': ltp,\n",
        "                            'profit_per_share': profit_per_share,\n",
        "                            'quantity': quantity,\n",
        "                            'pnl': realized_pnl,\n",
        "                            'time': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                        })\n",
        "\n",
        "                        buy_price = None\n",
        "                        last_order_id = None\n",
        "\n",
        "            # Advance time in paper trading mode\n",
        "            if TRADING_MODE in ['capital', 'quantity']:\n",
        "                if not paper_data_handler.advance_time():\n",
        "                    logging.info(\"No more data to simulate. Exiting gracefully...\")\n",
        "                    break\n",
        "\n",
        "            time.sleep(CHECK_INTERVAL)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            logging.info(\"Exiting gracefully due to keyboard interrupt.\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in main loop: {e}\")\n",
        "            time.sleep(CHECK_INTERVAL)\n",
        "\n",
        "    logging.info(f\"Exiting strategy. Total Realized PnL: {total_realized_pnl}\")\n",
        "    generate_trade_report(trades, total_realized_pnl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNs8Qm9zOOK8"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_loop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J0W1EnjZtNv9"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "def fetch_stock_data_in_chunks(symbol, start_date, end_date, interval=\"1m\", output_csv=\"stock_data.csv\"):\n",
        "    \"\"\"\n",
        "    Fetches historical stock data in chunks to handle limitations of Yahoo Finance API for '1m' interval.\n",
        "    Args:\n",
        "        symbol (str): Stock symbol (e.g., \"AAPL\").\n",
        "        start_date (str): Start date in \"YYYY-MM-DD\" format.\n",
        "        end_date (str): End date in \"YYYY-MM-DD\" format.\n",
        "        interval (str): Data interval (e.g., \"1m\", \"5m\").\n",
        "        output_csv (str): Output CSV file name.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        start = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "        end = datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "\n",
        "        all_data = []\n",
        "\n",
        "        logging.info(f\"Fetching {interval} data for {symbol} from {start_date} to {end_date}...\")\n",
        "\n",
        "        while start < end:\n",
        "            chunk_end = start + datetime.timedelta(days=7)  # Yahoo allows up to 7 days for '1m' interval\n",
        "            if chunk_end > end:\n",
        "                chunk_end = end\n",
        "\n",
        "            logging.info(f\"Fetching data for {symbol} from {start.strftime('%Y-%m-%d')} to {chunk_end.strftime('%Y-%m-%d')}...\")\n",
        "            data = yf.download(tickers=symbol, start=start.strftime('%Y-%m-%d'), end=chunk_end.strftime('%Y-%m-%d'), interval=interval)\n",
        "\n",
        "            if not data.empty:\n",
        "                # Rename the Datetime index to 'date' and reset index\n",
        "                data = data.rename_axis('date').reset_index()\n",
        "\n",
        "                # Rename columns to match desired output\n",
        "                rename_map = {\n",
        "                    'date': 'date',\n",
        "                    'High': 'high',\n",
        "                    'Close': 'close',\n",
        "                    'Low': 'low',\n",
        "                    'Open': 'open',\n",
        "                    'Volume': 'volume'\n",
        "                }\n",
        "                # Map only the desired columns\n",
        "                data = data[['date', 'High', 'Close', 'Low', 'Open', 'Volume']].rename(columns=rename_map)\n",
        "\n",
        "                all_data.append(data)\n",
        "                logging.info(f\"Data fetched for {symbol} from {start.strftime('%Y-%m-%d')} to {chunk_end.strftime('%Y-%m-%d')} ({len(data)} rows).\")\n",
        "            else:\n",
        "                logging.warning(f\"No data found for {symbol} from {start.strftime('%Y-%m-%d')} to {chunk_end.strftime('%Y-%m-%d')}.\")\n",
        "\n",
        "            # Move start to the next day after the current chunk\n",
        "            start = chunk_end\n",
        "\n",
        "        # Combine all chunks into one DataFrame\n",
        "        if all_data:\n",
        "            combined_data = pd.concat(all_data)\n",
        "            combined_data.reset_index(drop=True, inplace=True)  # Ensure clean index for the final DataFrame\n",
        "\n",
        "            # Drop the first row\n",
        "            combined_data = combined_data.iloc[1:]\n",
        "\n",
        "            # Save to CSV\n",
        "            logging.info(f\"Saving combined data to {output_csv}...\")\n",
        "            combined_data.to_csv(output_csv, index=False)\n",
        "            logging.info(f\"Data saved successfully to {output_csv}.\")\n",
        "        else:\n",
        "            logging.warning(\"No data fetched for the entire range.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error fetching stock data for {symbol}: {e}\", exc_info=True)\n",
        "\n",
        "# Example usage\n",
        "# fetch_stock_data_in_chunks(\"SBIN.NS\", \"2024-01-01\", \"2024-12-31\", interval=\"1m\", output_csv=\"sbin.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-01-01 -> 2024-01-08) (Yahoo error = \"1m data not available for startTime=1704047400 and endTime=1704652200. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-01-01 to 2024-01-08.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-01-08 -> 2024-01-15) (Yahoo error = \"1m data not available for startTime=1704652200 and endTime=1705257000. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-01-08 to 2024-01-15.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-01-15 -> 2024-01-22) (Yahoo error = \"1m data not available for startTime=1705257000 and endTime=1705861800. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-01-15 to 2024-01-22.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-01-22 -> 2024-01-29) (Yahoo error = \"1m data not available for startTime=1705861800 and endTime=1706466600. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-01-22 to 2024-01-29.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-01-29 -> 2024-02-05) (Yahoo error = \"1m data not available for startTime=1706466600 and endTime=1707071400. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-01-29 to 2024-02-05.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-02-05 -> 2024-02-12) (Yahoo error = \"1m data not available for startTime=1707071400 and endTime=1707676200. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-02-05 to 2024-02-12.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-02-12 -> 2024-02-19) (Yahoo error = \"1m data not available for startTime=1707676200 and endTime=1708281000. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-02-12 to 2024-02-19.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-02-19 -> 2024-02-26) (Yahoo error = \"1m data not available for startTime=1708281000 and endTime=1708885800. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-02-19 to 2024-02-26.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-02-26 -> 2024-03-04) (Yahoo error = \"1m data not available for startTime=1708885800 and endTime=1709490600. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-02-26 to 2024-03-04.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-03-04 -> 2024-03-11) (Yahoo error = \"1m data not available for startTime=1709490600 and endTime=1710095400. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-03-04 to 2024-03-11.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-03-11 -> 2024-03-18) (Yahoo error = \"1m data not available for startTime=1710095400 and endTime=1710700200. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-03-11 to 2024-03-18.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-03-18 -> 2024-03-25) (Yahoo error = \"1m data not available for startTime=1710700200 and endTime=1711305000. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-03-18 to 2024-03-25.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-03-25 -> 2024-04-01) (Yahoo error = \"1m data not available for startTime=1711305000 and endTime=1711909800. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-03-25 to 2024-04-01.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-04-01 -> 2024-04-08) (Yahoo error = \"1m data not available for startTime=1711909800 and endTime=1712514600. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-04-01 to 2024-04-08.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-04-08 -> 2024-04-15) (Yahoo error = \"1m data not available for startTime=1712514600 and endTime=1713119400. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-04-08 to 2024-04-15.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-04-15 -> 2024-04-22) (Yahoo error = \"1m data not available for startTime=1713119400 and endTime=1713724200. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-04-15 to 2024-04-22.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-04-22 -> 2024-04-29) (Yahoo error = \"1m data not available for startTime=1713724200 and endTime=1714329000. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-04-22 to 2024-04-29.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-04-29 -> 2024-05-06) (Yahoo error = \"1m data not available for startTime=1714329000 and endTime=1714933800. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-04-29 to 2024-05-06.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-05-06 -> 2024-05-13) (Yahoo error = \"1m data not available for startTime=1714933800 and endTime=1715538600. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-05-06 to 2024-05-13.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-05-13 -> 2024-05-20) (Yahoo error = \"1m data not available for startTime=1715538600 and endTime=1716143400. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-05-13 to 2024-05-20.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-05-20 -> 2024-05-27) (Yahoo error = \"1m data not available for startTime=1716143400 and endTime=1716748200. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-05-20 to 2024-05-27.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-05-27 -> 2024-06-03) (Yahoo error = \"1m data not available for startTime=1716748200 and endTime=1717353000. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-05-27 to 2024-06-03.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-06-03 -> 2024-06-10) (Yahoo error = \"1m data not available for startTime=1717353000 and endTime=1717957800. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-06-03 to 2024-06-10.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-06-10 -> 2024-06-17) (Yahoo error = \"1m data not available for startTime=1717957800 and endTime=1718562600. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-06-10 to 2024-06-17.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-06-17 -> 2024-06-24) (Yahoo error = \"1m data not available for startTime=1718562600 and endTime=1719167400. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-06-17 to 2024-06-24.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-06-24 -> 2024-07-01) (Yahoo error = \"1m data not available for startTime=1719167400 and endTime=1719772200. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-06-24 to 2024-07-01.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-07-01 -> 2024-07-08) (Yahoo error = \"1m data not available for startTime=1719772200 and endTime=1720377000. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-07-01 to 2024-07-08.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-07-08 -> 2024-07-15) (Yahoo error = \"1m data not available for startTime=1720377000 and endTime=1720981800. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-07-08 to 2024-07-15.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-07-15 -> 2024-07-22) (Yahoo error = \"1m data not available for startTime=1720981800 and endTime=1721586600. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-07-15 to 2024-07-22.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-07-22 -> 2024-07-29) (Yahoo error = \"1m data not available for startTime=1721586600 and endTime=1722191400. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-07-22 to 2024-07-29.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-07-29 -> 2024-08-05) (Yahoo error = \"1m data not available for startTime=1722191400 and endTime=1722796200. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-07-29 to 2024-08-05.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-08-05 -> 2024-08-12) (Yahoo error = \"1m data not available for startTime=1722796200 and endTime=1723401000. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-08-05 to 2024-08-12.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-08-12 -> 2024-08-19) (Yahoo error = \"1m data not available for startTime=1723401000 and endTime=1724005800. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-08-12 to 2024-08-19.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-08-19 -> 2024-08-26) (Yahoo error = \"1m data not available for startTime=1724005800 and endTime=1724610600. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-08-19 to 2024-08-26.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-08-26 -> 2024-09-02) (Yahoo error = \"1m data not available for startTime=1724610600 and endTime=1725215400. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-08-26 to 2024-09-02.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-09-02 -> 2024-09-09) (Yahoo error = \"1m data not available for startTime=1725215400 and endTime=1725820200. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-09-02 to 2024-09-09.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-09-09 -> 2024-09-16) (Yahoo error = \"1m data not available for startTime=1725820200 and endTime=1726425000. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-09-09 to 2024-09-16.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-09-16 -> 2024-09-23) (Yahoo error = \"1m data not available for startTime=1726425000 and endTime=1727029800. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-09-16 to 2024-09-23.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-09-23 -> 2024-09-30) (Yahoo error = \"1m data not available for startTime=1727029800 and endTime=1727634600. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-09-23 to 2024-09-30.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-09-30 -> 2024-10-07) (Yahoo error = \"1m data not available for startTime=1727634600 and endTime=1728239400. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-09-30 to 2024-10-07.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-10-07 -> 2024-10-14) (Yahoo error = \"1m data not available for startTime=1728239400 and endTime=1728844200. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-10-07 to 2024-10-14.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-10-14 -> 2024-10-21) (Yahoo error = \"1m data not available for startTime=1728844200 and endTime=1729449000. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-10-14 to 2024-10-21.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-10-21 -> 2024-10-28) (Yahoo error = \"1m data not available for startTime=1729449000 and endTime=1730053800. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-10-21 to 2024-10-28.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-10-28 -> 2024-11-04) (Yahoo error = \"1m data not available for startTime=1730053800 and endTime=1730658600. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-10-28 to 2024-11-04.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-11-04 -> 2024-11-11) (Yahoo error = \"1m data not available for startTime=1730658600 and endTime=1731263400. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-11-04 to 2024-11-11.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-11-11 -> 2024-11-18) (Yahoo error = \"1m data not available for startTime=1731263400 and endTime=1731868200. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-11-11 to 2024-11-18.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-11-18 -> 2024-11-25) (Yahoo error = \"1m data not available for startTime=1731868200 and endTime=1732473000. The requested range must be within the last 30 days.\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-11-18 to 2024-11-25.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-12-23 -> 2024-12-30) (Yahoo error = \"Data doesn\\'t exist for startDate = 1734892200, endDate = 1735497000\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-12-23 to 2024-12-30.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['SBIN.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1m 2024-12-30 -> 2024-12-31) (Yahoo error = \"Data doesn\\'t exist for startDate = 1735497000, endDate = 1735583400\")')\n",
            "WARNING:root:No data found for SBIN.NS from 2024-12-30 to 2024-12-31.\n"
          ]
        }
      ],
      "source": [
        "fetch_stock_data_in_chunks(\"SBIN.NS\", \"2024-01-01\", \"2024-12-31\", interval=\"1m\", output_csv=\"sbin.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        date        high       close         low   open  \\\n",
            "0  2024-11-25 03:46:00+00:00  842.349976  837.400024  836.549988  840.5   \n",
            "\n",
            "   volume  \n",
            "0  248009  \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>high</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024-11-25 03:47:00+00:00</td>\n",
              "      <td>839.799988</td>\n",
              "      <td>838.049988</td>\n",
              "      <td>837.450012</td>\n",
              "      <td>837.450012</td>\n",
              "      <td>127003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2024-11-25 03:48:00+00:00</td>\n",
              "      <td>841.549988</td>\n",
              "      <td>841.400024</td>\n",
              "      <td>837.650024</td>\n",
              "      <td>838.049988</td>\n",
              "      <td>401687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2024-11-25 03:49:00+00:00</td>\n",
              "      <td>842.000000</td>\n",
              "      <td>839.450012</td>\n",
              "      <td>838.200012</td>\n",
              "      <td>841.500000</td>\n",
              "      <td>748811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2024-11-25 03:50:00+00:00</td>\n",
              "      <td>839.400024</td>\n",
              "      <td>837.349976</td>\n",
              "      <td>837.099976</td>\n",
              "      <td>838.750000</td>\n",
              "      <td>149407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2024-11-25 03:51:00+00:00</td>\n",
              "      <td>838.700012</td>\n",
              "      <td>837.099976</td>\n",
              "      <td>836.900024</td>\n",
              "      <td>837.299988</td>\n",
              "      <td>130926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6684</th>\n",
              "      <td>2024-12-18 09:54:00+00:00</td>\n",
              "      <td>840.500000</td>\n",
              "      <td>840.500000</td>\n",
              "      <td>840.000000</td>\n",
              "      <td>840.400024</td>\n",
              "      <td>26950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6685</th>\n",
              "      <td>2024-12-18 09:55:00+00:00</td>\n",
              "      <td>840.650024</td>\n",
              "      <td>839.799988</td>\n",
              "      <td>839.799988</td>\n",
              "      <td>840.400024</td>\n",
              "      <td>42701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6686</th>\n",
              "      <td>2024-12-18 09:57:00+00:00</td>\n",
              "      <td>840.849976</td>\n",
              "      <td>840.700012</td>\n",
              "      <td>840.299988</td>\n",
              "      <td>840.599976</td>\n",
              "      <td>62829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6687</th>\n",
              "      <td>2024-12-18 09:58:00+00:00</td>\n",
              "      <td>840.599976</td>\n",
              "      <td>840.599976</td>\n",
              "      <td>840.599976</td>\n",
              "      <td>840.599976</td>\n",
              "      <td>332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6688</th>\n",
              "      <td>2024-12-18 09:59:00+00:00</td>\n",
              "      <td>840.750000</td>\n",
              "      <td>840.750000</td>\n",
              "      <td>840.099976</td>\n",
              "      <td>840.700012</td>\n",
              "      <td>52630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6689 rows  6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                           date        high       close         low  \\\n",
              "0     2024-11-25 03:47:00+00:00  839.799988  838.049988  837.450012   \n",
              "1     2024-11-25 03:48:00+00:00  841.549988  841.400024  837.650024   \n",
              "2     2024-11-25 03:49:00+00:00  842.000000  839.450012  838.200012   \n",
              "3     2024-11-25 03:50:00+00:00  839.400024  837.349976  837.099976   \n",
              "4     2024-11-25 03:51:00+00:00  838.700012  837.099976  836.900024   \n",
              "...                         ...         ...         ...         ...   \n",
              "6684  2024-12-18 09:54:00+00:00  840.500000  840.500000  840.000000   \n",
              "6685  2024-12-18 09:55:00+00:00  840.650024  839.799988  839.799988   \n",
              "6686  2024-12-18 09:57:00+00:00  840.849976  840.700012  840.299988   \n",
              "6687  2024-12-18 09:58:00+00:00  840.599976  840.599976  840.599976   \n",
              "6688  2024-12-18 09:59:00+00:00  840.750000  840.750000  840.099976   \n",
              "\n",
              "            open  volume  \n",
              "0     837.450012  127003  \n",
              "1     838.049988  401687  \n",
              "2     841.500000  748811  \n",
              "3     838.750000  149407  \n",
              "4     837.299988  130926  \n",
              "...          ...     ...  \n",
              "6684  840.400024   26950  \n",
              "6685  840.400024   42701  \n",
              "6686  840.599976   62829  \n",
              "6687  840.599976     332  \n",
              "6688  840.700012   52630  \n",
              "\n",
              "[6689 rows x 6 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#code to load the csv file and get the first row\n",
        "CSV_FILE = \"sbin.csv\"\n",
        "df = pd.read_csv(CSV_FILE)\n",
        "print(df.head(1))\n",
        "\n",
        "#drop the first row\n",
        "df = df.iloc[1:]\n",
        "\n",
        "#save the dataframe to a new csv file\n",
        "df.to_csv(CSV_FILE, index=False)\n",
        "df_cleaned = pd.read_csv(CSV_FILE)\n",
        "df_cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "XGQPXZz-1r5t",
        "outputId": "f93037a9-bc04-406f-979f-d014fb14df82"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'date'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-ea1d65ac2fb8>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load and preprocess data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'date'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "RSI_PERIOD = 15\n",
        "SUPER_TREND_MULTIPLIER = 3\n",
        "SUPER_TREND_PERIOD = 10\n",
        "\n",
        "# Load and preprocess data\n",
        "df = pd.read_csv(CSV_FILE)\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "# Function to calculate RSI\n",
        "def calculate_rsi(series, period=14):\n",
        "    delta = series.diff()\n",
        "    gain = delta.where(delta > 0, 0.0)\n",
        "    loss = -delta.where(delta < 0, 0.0)\n",
        "    avg_gain = gain.rolling(window=period, min_periods=1).mean()\n",
        "    avg_loss = loss.rolling(window=period, min_periods=1).mean()\n",
        "    rs = avg_gain / avg_loss\n",
        "    rsi = 100.0 - (100.0 / (1.0 + rs))\n",
        "    return rsi\n",
        "\n",
        "# Function to calculate Supertrend\n",
        "def calculate_supertrend(df, period=10, multiplier=3):\n",
        "    \"\"\"\n",
        "    Calculates the Supertrend indicator.\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame with 'high', 'low', 'close' columns.\n",
        "        period (int): ATR period.\n",
        "        multiplier (float): Multiplier for ATR bands.\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with 'supertrend', 'upper_band', 'lower_band', and 'trend'.\n",
        "    \"\"\"\n",
        "    # Calculate Average True Range (ATR)\n",
        "    hl2 = (df['high'] + df['low']) / 2\n",
        "    df['atr'] = df['high'].combine(df['low'], max) - df['low'].combine(df['close'], min)\n",
        "    df['atr'] = df['atr'].rolling(window=period).mean()\n",
        "\n",
        "    # Calculate upper and lower bands\n",
        "    df['upper_band'] = hl2 + (multiplier * df['atr'])\n",
        "    df['lower_band'] = hl2 - (multiplier * df['atr'])\n",
        "    df['supertrend'] = np.nan  # Initialize supertrend column\n",
        "\n",
        "    # Initialize trend variable\n",
        "    in_uptrend = True\n",
        "\n",
        "    # Iteratively calculate Supertrend\n",
        "    for i in range(1, len(df)):\n",
        "        if df['close'].iloc[i] > df['upper_band'].iloc[i - 1]:\n",
        "            in_uptrend = True\n",
        "        elif df['close'].iloc[i] < df['lower_band'].iloc[i - 1]:\n",
        "            in_uptrend = False\n",
        "\n",
        "        # Update supertrend based on the trend direction\n",
        "        if in_uptrend:\n",
        "            df.loc[i, 'supertrend'] = df['lower_band'].iloc[i]\n",
        "        else:\n",
        "            df.loc[i, 'supertrend'] = df['upper_band'].iloc[i]\n",
        "\n",
        "    # Identify trend direction\n",
        "    df['trend'] = np.where(df['close'] > df['supertrend'], 'up', 'down')\n",
        "\n",
        "    # Clean up intermediate columns\n",
        "    df.drop(['atr'], axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "# Calculate indicators\n",
        "df['rsi'] = calculate_rsi(df['close'], RSI_PERIOD)\n",
        "df = calculate_supertrend(df, period=SUPER_TREND_PERIOD, multiplier=SUPER_TREND_MULTIPLIER)\n",
        "\n",
        "# Define Buy and Sell signals\n",
        "df['buy_signal'] = np.where((df['trend'] == 'up') & (df['rsi'] < 30), df['close'], np.nan)\n",
        "df['sell_signal'] = np.where((df['trend'] == 'down') & (df['rsi'] > 70), df['close'], np.nan)\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(14, 10))\n",
        "\n",
        "# Price and Supertrend Plot\n",
        "plt.plot(df['date'], df['close'], label='Close Price', color='blue')\n",
        "plt.plot(df['date'], df['supertrend'], label='Supertrend', color='green')\n",
        "\n",
        "# Buy/Sell signals\n",
        "plt.scatter(df['date'], df['buy_signal'], label='Buy Signal', color='green', marker='^', s=100, zorder=5)\n",
        "plt.scatter(df['date'], df['sell_signal'], label='Sell Signal', color='red', marker='v', s=100, zorder=5)\n",
        "\n",
        "plt.title('Price with Supertrend and Buy/Sell Signals')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "# RSI Plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(df['date'], df['rsi'], label='RSI', color='orange')\n",
        "plt.axhline(70, color='red', linestyle='--', label='Overbought (70)')\n",
        "plt.axhline(30, color='green', linestyle='--', label='Oversold (30)')\n",
        "\n",
        "plt.scatter(df['date'], df['rsi'], c=np.where(df['rsi'] < 30, 'green', np.where(df['rsi'] > 70, 'red', 'orange')), label='RSI Signal', s=10)\n",
        "\n",
        "plt.title('RSI with Buy/Sell Signals')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(\"sbin_with_signals.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jugaad_data in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (0.26)\n",
            "Requirement already satisfied: requests in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from jugaad_data) (2.32.3)\n",
            "Requirement already satisfied: click==7.1.2 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from jugaad_data) (7.1.2)\n",
            "Requirement already satisfied: appdirs==1.4.4 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from jugaad_data) (1.4.4)\n",
            "Requirement already satisfied: beautifulsoup4==4.9.3 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from jugaad_data) (4.9.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from beautifulsoup4==4.9.3->jugaad_data) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from requests->jugaad_data) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from requests->jugaad_data) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from requests->jugaad_data) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from requests->jugaad_data) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install jugaad_data\n",
        "from datetime import date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "from jugaad_data.nse import stock_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "ename": "JSONDecodeError",
          "evalue": "Extra data: line 1 column 2 (char 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "File \u001b[0;32m~/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages/requests/models.py:974\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
            "File \u001b[0;32m/opt/datadog-packages/datadog-apm-library-python/2.12.2/ddtrace_pkgs/site-packages-ddtrace-py3.11-manylinux2014/ddtrace/appsec/_iast/_patches/json_tainting.py:43\u001b[0m, in \u001b[0;36mwrapped_loads\u001b[0;34m(wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_taint_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m taint_structure\n\u001b[0;32m---> 43\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m asm_config\u001b[38;5;241m.\u001b[39m_iast_enabled:\n",
            "File \u001b[0;32m/usr/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/usr/lib/python3.11/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 1 column 2 (char 1)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mstock_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRELIANCE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2020\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2020\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEQ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages/jugaad_data/nse/history.py:175\u001b[0m, in \u001b[0;36mstock_df\u001b[0;34m(symbol, from_date, to_date, series)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install pandas using \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m pip install pandas\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 175\u001b[0m raw \u001b[38;5;241m=\u001b[39m \u001b[43mstock_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(raw)[stock_select_headers]\n\u001b[1;32m    177\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m stock_final_headers\n",
            "File \u001b[0;32m~/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages/jugaad_data/nse/history.py:113\u001b[0m, in \u001b[0;36mNSEHistory.stock_raw\u001b[0;34m(self, symbol, from_date, to_date, series)\u001b[0m\n\u001b[1;32m    110\u001b[0m params \u001b[38;5;241m=\u001b[39m [(symbol, x[\u001b[38;5;241m0\u001b[39m], x[\u001b[38;5;241m1\u001b[39m], series) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(date_ranges)]\n\u001b[1;32m    111\u001b[0m chunks \u001b[38;5;241m=\u001b[39m ut\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stock, params, max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers)\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(chunks))\n",
            "File \u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
            "File \u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
            "File \u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "File \u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
            "File \u001b[0;32m/opt/datadog-packages/datadog-apm-library-python/2.12.2/ddtrace_pkgs/site-packages-ddtrace-py3.11-manylinux2014/ddtrace/contrib/internal/futures/threading.py:36\u001b[0m, in \u001b[0;36m_wrap_execution\u001b[0;34m(ctx, fn, args, kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     ddtrace\u001b[38;5;241m.\u001b[39mtracer\u001b[38;5;241m.\u001b[39mcontext_provider\u001b[38;5;241m.\u001b[39mactivate(ctx)\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages/jugaad_data/util.py:109\u001b[0m, in \u001b[0;36mcached.<locals>._cached.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(cache_dir):\n\u001b[1;32m    108\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(cache_dir)\n\u001b[0;32m--> 109\u001b[0m j \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m    111\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(j, fp)        \n",
            "File \u001b[0;32m~/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages/jugaad_data/nse/history.py:80\u001b[0m, in \u001b[0;36mNSEHistory._stock\u001b[0;34m(self, symbol, from_date, to_date, series)\u001b[0m\n\u001b[1;32m     73\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m'\u001b[39m: symbol,\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m'\u001b[39m: from_date\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m'\u001b[39m: to_date\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(series),\n\u001b[1;32m     78\u001b[0m }\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstock_history\u001b[39m\u001b[38;5;124m\"\u001b[39m, params)\n\u001b[0;32m---> 80\u001b[0m j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m j[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[0;32m~/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages/requests/models.py:978\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[0;32m--> 978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 1 column 2 (char 1)"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:ddtrace.vendor.dogstatsd:Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 7 additional messages skipped\n",
            "2024-12-18 23:59:02,283 WARNING [ddtrace.vendor.dogstatsd] [base.py:1031] [dd.service=python_files dd.env= dd.version= dd.trace_id=0 dd.span_id=0] - Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 7 additional messages skipped\n",
            "WARNING:ddtrace.vendor.dogstatsd:Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "2024-12-19 00:00:02,293 WARNING [ddtrace.vendor.dogstatsd] [base.py:1031] [dd.service=python_files dd.env= dd.version= dd.trace_id=0 dd.span_id=0] - Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "WARNING:ddtrace.vendor.dogstatsd:Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "2024-12-19 00:01:02,302 WARNING [ddtrace.vendor.dogstatsd] [base.py:1031] [dd.service=python_files dd.env= dd.version= dd.trace_id=0 dd.span_id=0] - Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "WARNING:ddtrace.vendor.dogstatsd:Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "2024-12-19 00:02:02,311 WARNING [ddtrace.vendor.dogstatsd] [base.py:1031] [dd.service=python_files dd.env= dd.version= dd.trace_id=0 dd.span_id=0] - Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "WARNING:ddtrace.vendor.dogstatsd:Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "2024-12-19 00:03:02,323 WARNING [ddtrace.vendor.dogstatsd] [base.py:1031] [dd.service=python_files dd.env= dd.version= dd.trace_id=0 dd.span_id=0] - Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "WARNING:ddtrace.vendor.dogstatsd:Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "2024-12-19 00:04:02,335 WARNING [ddtrace.vendor.dogstatsd] [base.py:1031] [dd.service=python_files dd.env= dd.version= dd.trace_id=0 dd.span_id=0] - Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "WARNING:ddtrace.vendor.dogstatsd:Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "2024-12-19 00:05:02,350 WARNING [ddtrace.vendor.dogstatsd] [base.py:1031] [dd.service=python_files dd.env= dd.version= dd.trace_id=0 dd.span_id=0] - Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "WARNING:ddtrace.vendor.dogstatsd:Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "2024-12-19 00:06:02,362 WARNING [ddtrace.vendor.dogstatsd] [base.py:1031] [dd.service=python_files dd.env= dd.version= dd.trace_id=0 dd.span_id=0] - Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "WARNING:ddtrace.vendor.dogstatsd:Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "2024-12-19 00:07:02,373 WARNING [ddtrace.vendor.dogstatsd] [base.py:1031] [dd.service=python_files dd.env= dd.version= dd.trace_id=0 dd.span_id=0] - Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "WARNING:ddtrace.vendor.dogstatsd:Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "2024-12-19 00:08:02,385 WARNING [ddtrace.vendor.dogstatsd] [base.py:1031] [dd.service=python_files dd.env= dd.version= dd.trace_id=0 dd.span_id=0] - Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "WARNING:ddtrace.vendor.dogstatsd:Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "2024-12-19 00:09:02,395 WARNING [ddtrace.vendor.dogstatsd] [base.py:1031] [dd.service=python_files dd.env= dd.version= dd.trace_id=0 dd.span_id=0] - Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "WARNING:ddtrace.vendor.dogstatsd:Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "2024-12-19 00:10:02,405 WARNING [ddtrace.vendor.dogstatsd] [base.py:1031] [dd.service=python_files dd.env= dd.version= dd.trace_id=0 dd.span_id=0] - Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "WARNING:ddtrace.vendor.dogstatsd:Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "2024-12-19 00:11:02,418 WARNING [ddtrace.vendor.dogstatsd] [base.py:1031] [dd.service=python_files dd.env= dd.version= dd.trace_id=0 dd.span_id=0] - Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "WARNING:ddtrace.vendor.dogstatsd:Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "2024-12-19 00:12:02,429 WARNING [ddtrace.vendor.dogstatsd] [base.py:1031] [dd.service=python_files dd.env= dd.version= dd.trace_id=0 dd.span_id=0] - Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "WARNING:ddtrace.vendor.dogstatsd:Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "2024-12-19 00:13:02,440 WARNING [ddtrace.vendor.dogstatsd] [base.py:1031] [dd.service=python_files dd.env= dd.version= dd.trace_id=0 dd.span_id=0] - Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "WARNING:ddtrace.vendor.dogstatsd:Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "2024-12-19 00:14:02,450 WARNING [ddtrace.vendor.dogstatsd] [base.py:1031] [dd.service=python_files dd.env= dd.version= dd.trace_id=0 dd.span_id=0] - Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "WARNING:ddtrace.vendor.dogstatsd:Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n",
            "2024-12-19 00:15:02,460 WARNING [ddtrace.vendor.dogstatsd] [base.py:1031] [dd.service=python_files dd.env= dd.version= dd.trace_id=0 dd.span_id=0] - Error submitting packet: [Errno 2] No such file or directory, dropping the packet and closing the socket, 11 additional messages skipped\n"
          ]
        }
      ],
      "source": [
        "df1 = stock_df(symbol=\"RELIANCE\", from_date=date(2020,1,1), to_date=date(2020,1,30), series=\"EQ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df1' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf1\u001b[49m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df1' is not defined"
          ]
        }
      ],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jugaad-data in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (0.26)\n",
            "Requirement already satisfied: requests in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from jugaad-data) (2.32.3)\n",
            "Requirement already satisfied: click==7.1.2 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from jugaad-data) (7.1.2)\n",
            "Requirement already satisfied: appdirs==1.4.4 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from jugaad-data) (1.4.4)\n",
            "Requirement already satisfied: beautifulsoup4==4.9.3 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from jugaad-data) (4.9.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from beautifulsoup4==4.9.3->jugaad-data) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from requests->jugaad-data) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from requests->jugaad-data) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from requests->jugaad-data) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/sahil/Codebase/algo-trading-framework/venv/lib/python3.11/site-packages (from requests->jugaad-data) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install jugaad-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
